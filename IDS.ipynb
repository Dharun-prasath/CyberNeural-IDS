{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a98a50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11acd085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input features after one-hot encoding: (125973, 122)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Step 1: Load dataset\n",
    "# ---------------------------\n",
    "train_file = '/Users/pheonix/Documents/SRM/IDS/KDDTrain+.txt'\n",
    "\n",
    "columns = [\n",
    "    'duration','protocol_type','service','flag','src_bytes','dst_bytes','land',\n",
    "    'wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised',\n",
    "    'root_shell','su_attempted','num_root','num_file_creations','num_shells','num_access_files',\n",
    "    'num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate',\n",
    "    'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate',\n",
    "    'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate',\n",
    "    'attack','level'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(train_file, header=None, names=columns)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: One-Hot Encode categorical features\n",
    "# ---------------------------\n",
    "cat_cols = ['protocol_type','service','flag']\n",
    "df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Separate features & labels\n",
    "# ---------------------------\n",
    "X = df.drop(['attack','level'], axis=1)  # Features\n",
    "y_attack = df['attack']                  # For CNN+LSTM (known attack labels)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Scale numerical features\n",
    "# ---------------------------\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Shape of input features after one-hot encoding:\", X_scaled.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc153455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 23\n",
      "Attack label mapping: {'back': 0, 'buffer_overflow': 1, 'ftp_write': 2, 'guess_passwd': 3, 'imap': 4, 'ipsweep': 5, 'land': 6, 'loadmodule': 7, 'multihop': 8, 'neptune': 9, 'nmap': 10, 'normal': 11, 'perl': 12, 'phf': 13, 'pod': 14, 'portsweep': 15, 'rootkit': 16, 'satan': 17, 'smurf': 18, 'spy': 19, 'teardrop': 20, 'warezclient': 21, 'warezmaster': 22}\n",
      "Training features shape: (100778, 122)\n",
      "Test features shape: (25195, 122)\n",
      "Training labels shape: (100778,)\n",
      "Test labels shape: (25195,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# Step 5: Encode attack labels\n",
    "# ---------------------------\n",
    "le_attack = LabelEncoder()\n",
    "y_encoded = le_attack.fit_transform(y_attack)  # CNN+LSTM expects numeric labels\n",
    "\n",
    "print(\"Number of classes:\", len(le_attack.classes_))\n",
    "\n",
    "# Optional: check mapping\n",
    "attack_mapping = dict(zip(le_attack.classes_, range(len(le_attack.classes_))))\n",
    "print(\"Attack label mapping:\", attack_mapping)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 6: Split data into train and test\n",
    "# ---------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a40538ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0356 - val_loss: 0.0093\n",
      "Epoch 2/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 3/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 4/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 5/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 6/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 8/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 11/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 12/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 13/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 14/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 15/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 16/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 17/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 18/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 19/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 20/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 21/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 24/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 26/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 27/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 28/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 29/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 30/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 31/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 32/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 33/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 35/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 36/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 39/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 40/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 41/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 42/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 43/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 44/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 46/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 47/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 49/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 50/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# ---------------------------\n",
    "# Build AE\n",
    "# ---------------------------\n",
    "ae_input = layers.Input(shape=(input_dim,))\n",
    "# Encoder\n",
    "encoded = layers.Dense(64, activation='relu')(ae_input)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "# Bottleneck\n",
    "bottleneck = layers.Dense(16, activation='relu')(encoded)\n",
    "# Decoder\n",
    "decoded = layers.Dense(32, activation='relu')(bottleneck)\n",
    "decoded = layers.Dense(64, activation='relu')(decoded)\n",
    "decoded = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = models.Model(ae_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ---------------------------\n",
    "# Train AE (use X_train only)\n",
    "# ---------------------------\n",
    "history = autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save AE model\n",
    "autoencoder.save('ae_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb68aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.5100 - val_accuracy: 0.9632 - val_loss: 0.1276\n",
      "Epoch 2/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0902 - val_accuracy: 0.9764 - val_loss: 0.0718\n",
      "Epoch 3/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0564 - val_accuracy: 0.9857 - val_loss: 0.0532\n",
      "Epoch 4/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0427 - val_accuracy: 0.9864 - val_loss: 0.0435\n",
      "Epoch 5/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0366 - val_accuracy: 0.9879 - val_loss: 0.0384\n",
      "Epoch 6/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0319 - val_accuracy: 0.9886 - val_loss: 0.0369\n",
      "Epoch 7/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0292 - val_accuracy: 0.9902 - val_loss: 0.0316\n",
      "Epoch 8/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0265 - val_accuracy: 0.9925 - val_loss: 0.0278\n",
      "Epoch 9/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0244 - val_accuracy: 0.9905 - val_loss: 0.0309\n",
      "Epoch 10/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0230 - val_accuracy: 0.9916 - val_loss: 0.0263\n",
      "Epoch 11/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0220 - val_accuracy: 0.9926 - val_loss: 0.0251\n",
      "Epoch 12/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0212 - val_accuracy: 0.9921 - val_loss: 0.0263\n",
      "Epoch 13/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 0.0202 - val_accuracy: 0.9924 - val_loss: 0.0239\n",
      "Epoch 14/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0188 - val_accuracy: 0.9938 - val_loss: 0.0215\n",
      "Epoch 15/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0187 - val_accuracy: 0.9931 - val_loss: 0.0233\n",
      "Epoch 16/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0177 - val_accuracy: 0.9934 - val_loss: 0.0223\n",
      "Epoch 17/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0169 - val_accuracy: 0.9919 - val_loss: 0.0240\n",
      "Epoch 18/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0179 - val_accuracy: 0.9927 - val_loss: 0.0218\n",
      "Epoch 19/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0159 - val_accuracy: 0.9935 - val_loss: 0.0197\n",
      "Epoch 20/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0150 - val_accuracy: 0.9924 - val_loss: 0.0220\n",
      "Epoch 21/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0155 - val_accuracy: 0.9937 - val_loss: 0.0188\n",
      "Epoch 22/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0147 - val_accuracy: 0.9938 - val_loss: 0.0205\n",
      "Epoch 23/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0145 - val_accuracy: 0.9928 - val_loss: 0.0203\n",
      "Epoch 24/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0137 - val_accuracy: 0.9937 - val_loss: 0.0185\n",
      "Epoch 25/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0136 - val_accuracy: 0.9941 - val_loss: 0.0200\n",
      "Epoch 26/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0134 - val_accuracy: 0.9936 - val_loss: 0.0184\n",
      "Epoch 27/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9935 - val_loss: 0.0194\n",
      "Epoch 28/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9936 - val_loss: 0.0187\n",
      "Epoch 29/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0122 - val_accuracy: 0.9930 - val_loss: 0.0216\n",
      "Epoch 30/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0121 - val_accuracy: 0.9942 - val_loss: 0.0181\n",
      "Epoch 31/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0122 - val_accuracy: 0.9945 - val_loss: 0.0181\n",
      "Epoch 32/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0119 - val_accuracy: 0.9941 - val_loss: 0.0190\n",
      "Epoch 33/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0115 - val_accuracy: 0.9931 - val_loss: 0.0217\n",
      "Epoch 34/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0113 - val_accuracy: 0.9941 - val_loss: 0.0184\n",
      "Epoch 35/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0113 - val_accuracy: 0.9942 - val_loss: 0.0175\n",
      "Epoch 36/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0112 - val_accuracy: 0.9946 - val_loss: 0.0180\n",
      "Epoch 37/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0111 - val_accuracy: 0.9935 - val_loss: 0.0198\n",
      "Epoch 38/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0104 - val_accuracy: 0.9946 - val_loss: 0.0211\n",
      "Epoch 39/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.9943 - val_loss: 0.0180\n",
      "Epoch 40/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0106 - val_accuracy: 0.9955 - val_loss: 0.0152\n",
      "Epoch 41/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0099 - val_accuracy: 0.9949 - val_loss: 0.0179\n",
      "Epoch 42/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0102 - val_accuracy: 0.9951 - val_loss: 0.0187\n",
      "Epoch 43/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0098 - val_accuracy: 0.9941 - val_loss: 0.0174\n",
      "Epoch 44/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0097 - val_accuracy: 0.9950 - val_loss: 0.0157\n",
      "Epoch 45/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0097 - val_accuracy: 0.9945 - val_loss: 0.0182\n",
      "Epoch 46/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0096 - val_accuracy: 0.9946 - val_loss: 0.0177\n",
      "Epoch 47/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0091 - val_accuracy: 0.9948 - val_loss: 0.0187\n",
      "Epoch 48/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 0.9947 - val_loss: 0.0193\n",
      "Epoch 49/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0096 - val_accuracy: 0.9950 - val_loss: 0.0164\n",
      "Epoch 50/50\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0093 - val_accuracy: 0.9946 - val_loss: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Encode labels as one-hot for classification\n",
    "num_classes = len(le_attack.classes_)\n",
    "y_train_cat = to_categorical(y_train, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Reshape input for CNN+LSTM: (samples, timesteps, features_per_step)\n",
    "# Here, we treat the whole feature vector as a \"sequence of 1 step\" (can adjust)\n",
    "X_train_seq = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test_seq = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# ---------------------------\n",
    "# Build CNN+LSTM\n",
    "# ---------------------------\n",
    "cnn_lstm_input = layers.Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2]))\n",
    "x = layers.Conv1D(filters=64, kernel_size=1, activation='relu')(cnn_lstm_input)\n",
    "x = layers.MaxPooling1D(pool_size=1)(x)\n",
    "x = layers.LSTM(64, return_sequences=False)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "cnn_lstm_model = models.Model(cnn_lstm_input, output)\n",
    "cnn_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ---------------------------\n",
    "# Train CNN+LSTM\n",
    "# ---------------------------\n",
    "history_cnn_lstm = cnn_lstm_model.fit(\n",
    "    X_train_seq, y_train_cat,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save CNN+LSTM model\n",
    "cnn_lstm_model.save('cnn_lstm_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf018dc",
   "metadata": {},
   "source": [
    "# Model Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc7c77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step\n",
      "Reconstruction error stats:\n",
      "Min: 1.6785914952903164e-06\n",
      "Max: 0.04153541515780681\n",
      "Mean: 0.002877896018685787\n",
      "Threshold for unknown attack: 0.008459876365030237\n",
      "Number of unknown samples detected: 1260\n",
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step\n",
      "CNN+LSTM Test Accuracy: 0.9948402460805715\n",
      "Confusion Matrix:\n",
      " [[  184     0     0     0     0     0     0     0     0     0     0     7\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     3     0     0     0     0     0     0     0     0     0     3\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0    11     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     2     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0   706     0     0     0     0     3    11\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     4     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     1     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     2     0     0  8241     0     0\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     9     0     0     0     0   288     1\n",
      "      0     0     0     0     0     1     0     0     0]\n",
      " [    0     1     0     0     0     2     1     0     0     0     2 13454\n",
      "      0     0     1     0     1     1     0     6     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0    40     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     1     0     3\n",
      "      0     0   581     0     1     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    11\n",
      "      0     0     1     0   715     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     3\n",
      "      0     0     0     0     0   526     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     1     0   177     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    49\n",
      "      0     0     0     0     0     0     0   129     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     1     3]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           back       1.00      0.96      0.98       191\n",
      "buffer_overflow       0.75      0.50      0.60         6\n",
      "      ftp_write       0.00      0.00      0.00         2\n",
      "   guess_passwd       1.00      1.00      1.00        11\n",
      "           imap       1.00      1.00      1.00         2\n",
      "        ipsweep       0.98      0.98      0.98       720\n",
      "           land       0.57      1.00      0.73         4\n",
      "     loadmodule       1.00      0.50      0.67         2\n",
      "       multihop       0.00      0.00      0.00         1\n",
      "        neptune       1.00      1.00      1.00      8243\n",
      "           nmap       0.98      0.96      0.97       299\n",
      "         normal       0.99      1.00      1.00     13469\n",
      "            phf       0.00      0.00      0.00         1\n",
      "            pod       1.00      1.00      1.00        40\n",
      "      portsweep       1.00      0.99      0.99       586\n",
      "        rootkit       0.00      0.00      0.00         2\n",
      "          satan       1.00      0.98      0.99       727\n",
      "          smurf       1.00      0.99      1.00       529\n",
      "       teardrop       1.00      0.99      1.00       178\n",
      "    warezclient       0.95      0.72      0.82       178\n",
      "    warezmaster       1.00      0.75      0.86         4\n",
      "\n",
      "       accuracy                           0.99     25195\n",
      "      macro avg       0.77      0.73      0.74     25195\n",
      "   weighted avg       0.99      0.99      0.99     25195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pheonix/Documents/SRM/IDS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/pheonix/Documents/SRM/IDS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/pheonix/Documents/SRM/IDS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predict on test set\n",
    "X_test_recon = autoencoder.predict(X_test)\n",
    "\n",
    "# Compute reconstruction error (MSE per sample)\n",
    "recon_error = np.mean(np.power(X_test - X_test_recon, 2), axis=1)\n",
    "\n",
    "print(\"Reconstruction error stats:\")\n",
    "print(\"Min:\", np.min(recon_error))\n",
    "print(\"Max:\", np.max(recon_error))\n",
    "print(\"Mean:\", np.mean(recon_error))\n",
    "\n",
    "# Optional: set threshold for unknown attack\n",
    "threshold = np.percentile(recon_error, 95)  # e.g., top 5% as unknown\n",
    "print(\"Threshold for unknown attack:\", threshold)\n",
    "\n",
    "# Flag unknown attacks\n",
    "unknown_flags = recon_error > threshold\n",
    "print(\"Number of unknown samples detected:\", np.sum(unknown_flags))\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Predict on test sequences\n",
    "y_pred_prob = cnn_lstm_model.predict(X_test_seq)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"CNN+LSTM Test Accuracy:\", accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate classification report for only labels present in y_test\n",
    "unique_labels = np.unique(y_test)\n",
    "report = classification_report(\n",
    "    y_test, y_pred,\n",
    "    labels=unique_labels,\n",
    "    target_names=le_attack.inverse_transform(unique_labels)\n",
    ")\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "702075b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le_attack.save']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save MinMaxScaler\n",
    "joblib.dump(scaler, 'scaler.save')\n",
    "\n",
    "# Save LabelEncoder for attack classes\n",
    "joblib.dump(le_attack, 'le_attack.save')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d11e9058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Predicted Known Attack Class: normal\n"
     ]
    }
   ],
   "source": [
    "# Example: single test sample\n",
    "sample = X_test[3].reshape(1, -1)\n",
    "\n",
    "# 1. AE reconstruction error\n",
    "recon_err = np.mean(np.power(sample - autoencoder.predict(sample), 2))\n",
    "\n",
    "if recon_err > threshold:\n",
    "    print(\"Predicted: Unknown Attack\")\n",
    "else:\n",
    "    # 2. CNN+LSTM prediction\n",
    "    sample_seq = sample.reshape(1, 1, input_dim)\n",
    "    pred_class = np.argmax(cnn_lstm_model.predict(sample_seq), axis=1)[0]\n",
    "    print(\"Predicted Known Attack Class:\", le_attack.inverse_transform([pred_class])[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
